{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the same data we used in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (20.2.2)\n",
      "Processing /home/ec2-user/.cache/pip/wheels/de/5e/42/64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51/nltk-3.5-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from nltk) (4.44.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from nltk) (0.14.1)\n",
      "Collecting regex\n",
      "  Using cached regex-2020.7.14-cp36-cp36m-manylinux2010_x86_64.whl (660 kB)\n",
      "Requirement already satisfied, skipping upgrade: click in /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages (from nltk) (7.1.1)\n",
      "Installing collected packages: regex, nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.4.5\n",
      "    Uninstalling nltk-3.4.5:\n",
      "      Successfully uninstalled nltk-3.4.5\n",
      "Successfully installed nltk-3.5 regex-2020.7.14\n"
     ]
    }
   ],
   "source": [
    "#Upgrade dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"it was a clean game\",\n",
    "        \"oil companies lost over 25 millions yesterday\",\n",
    "        \"he scored three goals\",\n",
    "        \"their 3 game winning streak ended yesterday\",\n",
    "        \"The stock market started the day with profits\"\n",
    "]\n",
    "labels = [\"not_finance\", \"finance\", \"not_finance\", \"not_finance\", \"finance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode our labels. finance -> 0 and not_finance -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(labels):\n",
    "    if item == \"finance\":\n",
    "        labels[idx] = 0\n",
    "    else:\n",
    "        labels[idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Preprocess our text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "snow = SnowballStemmer('english') #initialising the snowball stemmer\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def process_texts(texts):\n",
    "    sentence_list = []\n",
    "    for sentence in texts:\n",
    "        item_list = []\n",
    "        for item in sentence.split():\n",
    "            if len(item)>2 and (item not in set(stop)):\n",
    "                item_list.append(snow.stem(item))\n",
    "        sentence_list.append(\" \".join(item_list))\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it was a clean game', 'oil companies lost over 25 millions yesterday', 'he scored three goals', 'their 3 game winning streak ended yesterday', 'The stock market started the day with profits']\n",
      "['clean game', 'oil compani lost million yesterday', 'score three goal', 'game win streak end yesterday', 'the stock market start day profit']\n"
     ]
    }
   ],
   "source": [
    "print(texts)\n",
    "print(process_texts(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Calculating Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean game', 'oil compani lost million yesterday', 'score three goal', 'game win streak end yesterday', 'the stock market start day profit']\n",
      "   clean  compani  day  end  game  goal  lost  market  million  oil  profit  \\\n",
      "0      1        0    0    0     1     0     0       0        0    0       0   \n",
      "1      0        1    0    0     0     0     1       0        1    1       0   \n",
      "2      0        0    0    0     0     1     0       0        0    0       0   \n",
      "3      0        0    0    1     1     0     0       0        0    0       0   \n",
      "4      0        0    1    0     0     0     0       1        0    0       1   \n",
      "\n",
      "   score  start  stock  streak  the  three  win  yesterday  \n",
      "0      0      0      0       0    0      0    0          0  \n",
      "1      0      0      0       0    0      0    0          1  \n",
      "2      1      0      0       0    0      1    0          0  \n",
      "3      0      0      0       1    0      0    1          1  \n",
      "4      0      1      1       0    1      0    0          0  \n",
      "['clean', 'compani', 'day', 'end', 'game', 'goal', 'lost', 'market', 'million', 'oil', 'profit', 'score', 'start', 'stock', 'streak', 'the', 'three', 'win', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "features = count_vectorizer.fit_transform(process_texts(texts))\n",
    "\n",
    "df = pd.DataFrame(features.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "print(process_texts(texts))\n",
    "print(df)\n",
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Fitting the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Pre-processing\n",
      "['learn stock market play game']\n",
      "*Vectorizing: Pay attention below, we have three non-zero terms. They correspond to our vocabulary words: stock, market and game\n",
      "[[0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "*Predicting\n",
      "Class: [1]\n",
      "Probabilities: [[0.44534731 0.55465269]]\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\"learn stock market playing this game\"]\n",
    "\n",
    "print(\"*Pre-processing\")\n",
    "print(process_texts(test_sentences))\n",
    "\n",
    "print(\"*Vectorizing: Pay attention below, we have three non-zero terms. They correspond to our vocabulary words: stock, market and game\")\n",
    "test_features = count_vectorizer.transform(process_texts(test_sentences))\n",
    "print(test_features.toarray())\n",
    "\n",
    "print(\"*Predicting\")\n",
    "print(\"Class:\", clf.predict(test_features))\n",
    "print(\"Probabilities:\", clf.predict_proba(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predicted \"non_finance\". "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
